# TRINETRA 2.0 - MILITARY-GRADE DARKNET INTELLIGENCE PLATFORM
## Complete Technical Documentation

---

## üéñÔ∏è EXECUTIVE SUMMARY

TRINETRA 2.0 represents a state-of-the-art darknet intelligence gathering platform designed for military-grade operations. This comprehensive system provides advanced threat detection, real-time monitoring, and sophisticated anonymity protection for intelligence operations in the dark web ecosystem.

**Version:** 2.0  
**Classification:** Military-Grade Intelligence Platform  
**Primary Mission:** Darknet Threat Intelligence & Monitoring  

---

## üìã TABLE OF CONTENTS

1. [System Architecture](#system-architecture)
2. [Core Components](#core-components)
3. [Security & OPSEC Features](#security--opsec-features)
4. [Database System](#database-system)
5. [Web Crawler Engine](#web-crawler-engine)
6. [Intelligence Dashboard](#intelligence-dashboard)
7. [Proxy & Anonymity Layer](#proxy--anonymity-layer)
8. [Testing & Validation Suite](#testing--validation-suite)
9. [Installation & Setup](#installation--setup)
10. [Operational Procedures](#operational-procedures)
11. [API Reference](#api-reference)
12. [Troubleshooting](#troubleshooting)

---

## üèóÔ∏è SYSTEM ARCHITECTURE

### Core Platform Stack
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TRINETRA 2.0 PLATFORM                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üéØ Intelligence Dashboard (Streamlit)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üï∑Ô∏è Web Crawler Engine (Scrapy)                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üóÑÔ∏è Database Layer (SQLite)                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üîí Security & OPSEC Manager                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üåê Proxy & Anonymity Layer (TOR/SOCKS5)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Technology Stack
- **Frontend:** Streamlit (Python-based web interface)
- **Backend:** Python 3.13+
- **Web Crawler:** Scrapy Framework
- **Database:** SQLite with WAL mode
- **Proxy Layer:** TOR + SOCKS5 + HTTP proxies
- **Security:** Custom OPSEC management system
- **Alerts:** Telegram Bot integration

---

## üîß CORE COMPONENTS

### 1. **Web Crawler Engine** (`crawler/spiders/tor_crawler.py`)

The heart of TRINETRA 2.0, featuring:

#### **OnionCrawler Class**
- **Purpose:** Advanced .onion domain crawling with military-grade features
- **Capabilities:**
  - Multi-threaded concurrent crawling
  - Dynamic User-Agent rotation
  - Proxy chain management
  - Content-type filtering
  - Keyword-based threat detection
  - Real-time progress monitoring

#### **Key Features:**
```python
# Advanced Settings
CONCURRENT_REQUESTS = 16
CONCURRENT_REQUESTS_PER_DOMAIN = 8
AUTOTHROTTLE_ENABLED = True
RETRY_TIMES = 8
DOWNLOAD_TIMEOUT = 45
```

#### **Security Features:**
- **Anti-Detection:** Randomized delays, headers, and user agents
- **Proxy Rotation:** Automatic switching between multiple proxy chains
- **Error Handling:** Comprehensive failure recovery mechanisms
- **Content Filtering:** Intelligent filtering of non-relevant content

#### **Threat Detection:**
- **Keyword Analysis:** Real-time scanning for threat indicators
- **Risk Assessment:** Automated threat level categorization (HIGH/MEDIUM/LOW)
- **Content Hashing:** Duplicate detection and prevention
- **Alert Generation:** Immediate notification system

### 2. **Intelligence Dashboard** (`dashboard.py`)

Professional-grade monitoring interface featuring:

#### **Dashboard Components:**
- **Real-time Metrics:** Live crawler statistics and performance
- **Threat Intelligence:** Advanced threat visualization and analysis
- **Alert Management:** Comprehensive alert monitoring and filtering
- **Analytics:** Historical data analysis and trend detection
- **Link Management:** Visited links tracking and analysis

#### **Advanced Features:**
```python
# Auto-refresh capabilities
st_autorefresh(interval=30000)  # 30-second refresh

# Professional theming
Glass-morphism UI with military-grade aesthetics
Real-time data visualization with Plotly
Interactive charts and graphs
```

#### **Security Dashboard:**
- **OPSEC Status:** Real-time operational security monitoring
- **Proxy Health:** Multi-proxy chain status monitoring
- **Threat Levels:** Color-coded threat assessment display
- **Performance Metrics:** System performance and efficiency tracking

### 3. **Database System** (`database/models.py`)

Military-grade data management system:

#### **Database Architecture:**
```sql
-- Core Tables
alerts              -- Threat intelligence alerts
crawled_pages       -- Visited page tracking
threat_intelligence -- Advanced threat data
non_http_links      -- Non-HTTP protocol tracking
keyword_tracking    -- Keyword analysis data
```

#### **Advanced Features:**
- **SQLite WAL Mode:** High-performance concurrent access
- **Thread Safety:** Multi-threaded operation support
- **Data Integrity:** ACID compliance with transaction support
- **Migration System:** Seamless JSON to SQLite migration
- **Performance Optimization:** Indexed queries and efficient storage

#### **Data Models:**
```python
class Alert:
    - timestamp: ISO format timestamp
    - url: Source URL
    - title: Page title
    - keywords_found: List of detected keywords
    - content_hash: MD5 hash for duplicate detection
    - threat_level: Risk assessment (HIGH/MEDIUM/LOW)

class CrawledPage:
    - url: Page URL
    - title: Page title
    - content_hash: Content fingerprint
    - timestamp: Crawl timestamp
    - response_code: HTTP status
    - processing_time: Performance metrics
    - page_size: Content size
    - links_found: Number of links discovered
```

### 4. **Security & OPSEC Manager** (`security/opsec_manager.py`)

Military-grade operational security system:

#### **OPSEC Features:**
- **Identity Protection:** Advanced anonymization techniques
- **Traffic Analysis Prevention:** Sophisticated timing and pattern obfuscation
- **Forensic Countermeasures:** Anti-forensic data handling
- **Operational Security:** Comprehensive OPSEC protocol enforcement

#### **Security Protocols:**
```python
# Advanced anonymization
- Multi-layer proxy chaining
- Dynamic circuit refresh
- Traffic timing randomization
- Metadata sanitization
- Secure data deletion
```

#### **Threat Mitigation:**
- **Counter-Intelligence:** Advanced detection evasion
- **Operational Security:** Protocol-based security enforcement
- **Data Protection:** Encrypted storage and transmission
- **Audit Trail:** Security event logging and monitoring

### 5. **Proxy & Anonymity Layer** (`crawler/middlewares/socks5_handler.py`)

Advanced proxy management system:

#### **Proxy Architecture:**
```python
# Multi-proxy support
TOR_PROXIES = [
    "http://127.0.0.1:8118",     # Privoxy HTTP
    "http://127.0.0.1:8119",     # Secondary HTTP
    "http://127.0.0.1:8120",     # Tertiary HTTP
    "socks5://127.0.0.1:9050",   # TOR SOCKS5
    "socks5://127.0.0.1:9051",   # Secondary SOCKS5
    "socks5://127.0.0.1:9052"    # Tertiary SOCKS5
]
```

#### **Enhanced Features:**
- **Proxy Rotation:** Automatic switching between proxy chains
- **Health Monitoring:** Real-time proxy status checking
- **Failover Support:** Automatic fallback mechanisms
- **Performance Optimization:** Latency-based proxy selection
- **Error Recovery:** Comprehensive error handling and recovery

#### **Security Features:**
- **Chain Validation:** Proxy chain integrity verification
- **Traffic Encryption:** End-to-end encryption support
- **Anonymity Verification:** Real-time anonymity testing
- **Circuit Management:** TOR circuit refresh and management

---

## üîí SECURITY & OPSEC FEATURES

### Military-Grade Security Architecture

#### **1. Multi-Layer Anonymization**
- **TOR Integration:** Advanced TOR network utilization
- **Proxy Chaining:** Multiple proxy layer protection
- **Traffic Obfuscation:** Advanced traffic pattern masking
- **Identity Compartmentalization:** Operational identity separation

#### **2. Anti-Detection Mechanisms**
```python
# Advanced User-Agent Rotation
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit...",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36..."
]

# Randomized Request Timing
DOWNLOAD_DELAY = random.uniform(2, 5)
RANDOMIZE_DOWNLOAD_DELAY = 0.5
```

#### **3. Operational Security Protocols**
- **Secure Communication:** Encrypted data transmission
- **Audit Logging:** Comprehensive security event logging
- **Access Control:** Role-based access management
- **Data Sanitization:** Secure data deletion and handling

#### **4. Counter-Intelligence Features**
- **Honeypot Detection:** Advanced trap identification
- **Behavioral Analysis:** Suspicious activity detection
- **Threat Assessment:** Real-time risk evaluation
- **Incident Response:** Automated security incident handling

---

## üóÑÔ∏è DATABASE SYSTEM

### Advanced Data Architecture

#### **Database Configuration:**
```python
# High-Performance Settings
PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA cache_size = 10000;
PRAGMA temp_store = MEMORY;
```

#### **Core Tables Structure:**

##### **1. Alerts Table**
```sql
CREATE TABLE alerts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp TEXT NOT NULL,
    url TEXT NOT NULL,
    title TEXT,
    keywords_found TEXT NOT NULL,
    content_hash TEXT UNIQUE,
    threat_level TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

##### **2. Crawled Pages Table**
```sql
CREATE TABLE crawled_pages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    url TEXT UNIQUE NOT NULL,
    title TEXT,
    content_hash TEXT,
    timestamp TEXT NOT NULL,
    response_code INTEGER,
    processing_time REAL,
    page_size INTEGER,
    links_found INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

##### **3. Threat Intelligence Table**
```sql
CREATE TABLE threat_intelligence (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    indicator_type TEXT NOT NULL,
    indicator_value TEXT NOT NULL,
    threat_level TEXT NOT NULL,
    confidence_score REAL,
    source_url TEXT,
    first_seen TIMESTAMP,
    last_seen TIMESTAMP,
    tags TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### **Database Operations:**

#### **Advanced Querying:**
```python
# Performance-optimized queries
def get_alerts(self, limit=100, threat_level=None):
    query = """
    SELECT * FROM alerts 
    WHERE (%s IS NULL OR threat_level = %s)
    ORDER BY timestamp DESC 
    LIMIT %s
    """
    
# Statistical analysis
def get_threat_statistics(self):
    return {
        'total_alerts': self.get_alert_count(),
        'alerts_by_level': self.get_alerts_by_level(),
        'total_pages': self.get_page_count(),
        'recent_activity': self.get_recent_activity()
    }
```

---

## üï∑Ô∏è WEB CRAWLER ENGINE

### Advanced Crawling Architecture

#### **Scrapy Configuration:**
```python
# Optimized Settings
CONCURRENT_REQUESTS = 16
CONCURRENT_REQUESTS_PER_DOMAIN = 8
AUTOTHROTTLE_ENABLED = True
AUTOTHROTTLE_START_DELAY = 1
AUTOTHROTTLE_MAX_DELAY = 10
AUTOTHROTTLE_TARGET_CONCURRENCY = 2.0
```

#### **Middleware Stack:**
```python
DOWNLOADER_MIDDLEWARES = {
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
    'scrapy.downloadermiddlewares.retry.RetryMiddleware': 90,
    'crawler.middlewares.socks5_handler.EnhancedProxyMiddleware': 100,
}
```

### **Crawler Features:**

#### **1. Intelligent Content Processing**
- **Content-Type Detection:** Automatic content type filtering
- **Binary File Skipping:** Efficient resource utilization
- **Link Extraction:** Advanced link discovery algorithms
- **Duplicate Detection:** Content hash-based deduplication

#### **2. Advanced Link Following**
```python
# Concurrent link processing
with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    futures = []
    for href in response.css("a::attr(href)").getall():
        full_url = urljoin(url, href)
        if self._should_crawl_url(full_url):
            futures.append(executor.submit(self.yield_request, response, full_url))
```

#### **3. Keyword-Based Threat Detection**
```python
# Real-time threat analysis
matched_keywords = [
    kw for kw in KEYWORDS 
    if re.search(rf"\b{re.escape(kw.lower())}\b", page_text)
]

# Threat level assessment
def _determine_threat_level(self, keywords):
    high_risk = ['bomb', 'terror', 'attack', 'kill', 'explosive']
    medium_risk = ['carding', 'hacking', 'drugs', 'malware']
    # Risk assessment logic
```

---

## üìä INTELLIGENCE DASHBOARD

### Professional Intelligence Interface

#### **Dashboard Architecture:**
```python
# Streamlit Configuration
st.set_page_config(
    page_title="üïµ TRINETRA 2.0",
    page_icon="üïµ",
    layout="wide",
    initial_sidebar_state="expanded"
)
```

#### **Core Dashboard Components:**

##### **1. Real-Time Metrics**
```python
# Live system metrics
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.metric("Total Alerts", len(alerts), delta=recent_alerts)
with col2:
    st.metric("Pages Crawled", len(visited), delta=recent_pages)
with col3:
    st.metric("Threat Level", highest_threat)
with col4:
    st.metric("System Status", "OPERATIONAL")
```

##### **2. Advanced Visualization**
```python
# Interactive charts
fig = px.line(
    x=timestamps, 
    y=alert_counts,
    title="Threat Intelligence Timeline",
    labels={'x': 'Time', 'y': 'Alert Count'}
)
st.plotly_chart(fig, use_container_width=True)
```

##### **3. Alert Management System**
- **Real-time Filtering:** Dynamic alert filtering and search
- **Threat Analysis:** Advanced threat pattern recognition
- **Export Capabilities:** Data export and reporting features
- **Historical Analysis:** Time-based threat intelligence analysis

### **Dashboard Features:**

#### **1. Military-Grade UI Design**
```css
/* Advanced styling */
.glass-container {
    backdrop-filter: blur(20px) saturate(180%);
    background: rgba(17, 25, 40, 0.3);
    border-radius: 20px;
    border: 1px solid rgba(147, 51, 234, 0.3);
    box-shadow: 0 8px 32px rgba(147, 51, 234, 0.2);
}
```

#### **2. Interactive Controls**
- **Real-time Refresh:** Auto-refresh capabilities
- **Manual Controls:** Start/stop crawler operations
- **Configuration:** Dynamic system configuration
- **Export Tools:** Professional reporting capabilities

---

## üåê PROXY & ANONYMITY LAYER

### Advanced Proxy Management

#### **Proxy Architecture:**
```python
class EnhancedProxyMiddleware:
    def __init__(self):
        self.proxies = self.load_proxy_list()
        self.current_proxy_index = 0
        self.proxy_health = {}
        self.circuit_refresh_counter = 0
```

#### **Proxy Features:**

##### **1. Multi-Proxy Support**
- **HTTP Proxies:** Standard HTTP proxy support
- **SOCKS5 Proxies:** Advanced SOCKS5 proxy integration
- **TOR Integration:** Native TOR network support
- **Proxy Chaining:** Multiple proxy layer protection

##### **2. Health Monitoring**
```python
def check_proxy_health(self, proxy):
    """Real-time proxy health verification"""
    try:
        response = requests.get(
            'http://httpbin.org/ip',
            proxies={'http': proxy, 'https': proxy},
            timeout=10
        )
        return response.status_code == 200
    except:
        return False
```

##### **3. Automatic Failover**
- **Health Checks:** Continuous proxy health monitoring
- **Automatic Switching:** Seamless proxy rotation
- **Error Recovery:** Comprehensive error handling
- **Performance Optimization:** Latency-based selection

### **Anonymity Features:**

#### **1. Traffic Obfuscation**
- **Timing Randomization:** Random delay injection
- **Pattern Masking:** Traffic pattern obfuscation
- **Header Randomization:** Dynamic header modification
- **Circuit Refresh:** Automatic TOR circuit renewal

#### **2. Identity Protection**
- **User-Agent Rotation:** Dynamic user agent switching
- **Fingerprint Resistance:** Browser fingerprint masking
- **Session Management:** Secure session handling
- **Metadata Sanitization:** Comprehensive metadata cleaning

---

## üß™ TESTING & VALIDATION SUITE

### Comprehensive Testing Framework

#### **Test Components:**

##### **1. Phase 1 Testing** (`test_phase1.py`)
- **Database Testing:** SQLite integration validation
- **Threading Safety:** Multi-threaded operation testing
- **Alert Operations:** Alert system functionality testing
- **Migration Testing:** JSON to SQLite migration validation

##### **2. Connectivity Testing** (`test_tor_connectivity.py`)
- **TOR Network:** TOR connectivity validation
- **Proxy Testing:** Proxy chain health verification
- **.onion Access:** Hidden service accessibility testing
- **Network Performance:** Connection speed and reliability testing

##### **3. SOCKS5 Testing** (`test_socks5.py`)
- **SOCKS5 Proxy:** SOCKS5 proxy functionality testing
- **Protocol Validation:** Protocol compliance verification
- **Performance Testing:** Connection speed and stability testing
- **Error Handling:** Failure recovery testing

##### **4. Crawler Testing** (`test_onion_crawler.py`)
- **Spider Functionality:** Crawler operation validation
- **Content Processing:** Content handling verification
- **Link Following:** Link discovery and following testing
- **Error Recovery:** Crawler resilience testing

##### **5. Method Testing** (`test_both_methods.py`)
- **Execution Methods:** Multiple execution method testing
- **Performance Comparison:** Method performance analysis
- **Compatibility Testing:** System compatibility verification
- **Integration Testing:** Component integration validation

### **Testing Protocols:**

#### **Automated Testing:**
```python
def run_all_tests():
    """Comprehensive test suite execution"""
    tests = [
        test_database_initialization,
        test_alert_operations,
        test_crawled_page_operations,
        test_threat_statistics,
        test_threading_safety,
        test_json_migration
    ]
    
    for test in tests:
        try:
            if test():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            failed += 1
            log_error(f"Test failed: {e}")
```

#### **Performance Benchmarking:**
- **Crawler Performance:** Speed and efficiency metrics
- **Database Performance:** Query execution time analysis
- **Proxy Performance:** Connection speed and reliability metrics
- **System Resource Usage:** Memory and CPU utilization monitoring

---

## üöÄ INSTALLATION & SETUP

### System Requirements

#### **Minimum Requirements:**
- **OS:** Linux (Kali Linux recommended)
- **Python:** 3.13+
- **RAM:** 4GB minimum, 8GB recommended
- **Storage:** 10GB free space
- **Network:** Stable internet connection

#### **Required Dependencies:**
```bash
# Core dependencies
pip install scrapy streamlit sqlite3 requests
pip install plotly pandas numpy wordcloud
pip install telegram-bot python-telegram-bot
pip install tqdm concurrent-futures hashlib
```

### **Installation Steps:**

#### **1. Clone Repository**
```bash
git clone https://github.com/Vectorindia1/Trinetra2.0.git
cd Trinetra2.0
```

#### **2. Install Dependencies**
```bash
pip install -r requirements.txt
```

#### **3. Configure TOR and Proxies**
```bash
# Install TOR
sudo apt-get install tor

# Configure Privoxy
sudo apt-get install privoxy

# Setup proxy configuration
sudo cp /etc/privoxy/config /etc/privoxy/config.backup
sudo nano /etc/privoxy/config
```

#### **4. Database Setup**
```bash
# Initialize database
python migrate_to_sqlite.py

# Verify database
python test_phase1.py
```

#### **5. Configure Telegram Bot**
```python
# Edit telegram_alert.py
TELEGRAM_BOT_TOKEN = "YOUR_BOT_TOKEN"
TELEGRAM_CHAT_ID = "YOUR_CHAT_ID"
```

### **Configuration Files:**

#### **1. Keyword Configuration** (`keyword.json`)
```json
{
    "india_keywords": [
        "bomb", "terror", "attack", "assassination",
        "drugs", "cocaine", "heroin", "meth",
        "hacking", "carding", "malware", "ransomware",
        "bitcoin", "monero", "deep web", "darknet"
    ]
}
```

#### **2. Proxy Configuration** (`PROXY_SETUP.md`)
- **TOR Configuration:** Complete TOR setup guide
- **Privoxy Setup:** HTTP proxy configuration
- **SOCKS5 Configuration:** Advanced SOCKS5 setup
- **Multi-Proxy Chaining:** Proxy chain configuration

---

## üéØ OPERATIONAL PROCEDURES

### Standard Operating Procedures

#### **1. System Startup**
```bash
# Start TOR service
sudo systemctl start tor

# Start Privoxy
sudo systemctl start privoxy

# Launch TRINETRA 2.0
./run_all.sh
```

#### **2. Crawler Operations**
```bash
# Start crawler with specific target
scrapy crawl onion -a start_url="http://example.onion"

# Monitor crawler progress
tail -f crawler.log

# View real-time dashboard
streamlit run dashboard.py
```

#### **3. Intelligence Analysis**
- **Dashboard Monitoring:** Real-time threat intelligence monitoring
- **Alert Analysis:** Comprehensive alert investigation procedures
- **Threat Assessment:** Risk evaluation and categorization
- **Reporting:** Intelligence report generation and distribution

### **Operational Security Procedures:**

#### **1. OPSEC Protocols**
- **Identity Protection:** Operational identity management
- **Communication Security:** Secure communication protocols
- **Data Handling:** Secure data processing and storage
- **Incident Response:** Security incident management

#### **2. Emergency Procedures**
- **System Shutdown:** Emergency shutdown protocols
- **Data Destruction:** Secure data deletion procedures
- **Compromise Response:** System compromise response
- **Recovery Operations:** System recovery and restoration

---

## üìö API REFERENCE

### Database API

#### **DatabaseManager Class**
```python
class DatabaseManager:
    def __init__(self, db_path="darknet_intelligence.db"):
        """Initialize database connection"""
        
    def insert_alert(self, alert: Alert) -> int:
        """Insert new threat alert"""
        
    def get_alerts(self, limit=100, threat_level=None) -> List[Alert]:
        """Retrieve threat alerts"""
        
    def get_threat_statistics(self) -> Dict:
        """Get comprehensive threat statistics"""
        
    def migrate_from_json(self, json_files: Dict) -> None:
        """Migrate data from JSON files"""
```

### Crawler API

#### **OnionCrawler Class**
```python
class OnionCrawler(scrapy.Spider):
    name = "onion"
    
    def __init__(self, start_url=None):
        """Initialize crawler with target URL"""
        
    def parse(self, response):
        """Process crawled page content"""
        
    def _determine_threat_level(self, keywords) -> str:
        """Assess threat level based on keywords"""
        
    def _should_skip_url(self, url) -> bool:
        """Determine if URL should be skipped"""
```

### Security API

#### **OPSEC Manager**
```python
class OpsecManager:
    def __init__(self):
        """Initialize OPSEC management system"""
        
    def validate_operational_security(self) -> bool:
        """Validate current OPSEC status"""
        
    def apply_security_protocols(self) -> None:
        """Apply security protocols"""
        
    def monitor_security_status(self) -> Dict:
        """Monitor security status"""
```

---

## üîß TROUBLESHOOTING

### Common Issues and Solutions

#### **1. Crawler Issues**

##### **Problem:** Crawler not starting
**Solution:**
```bash
# Check TOR service
sudo systemctl status tor

# Verify proxy configuration
curl --proxy socks5://127.0.0.1:9050 http://httpbin.org/ip

# Test crawler manually
scrapy crawl onion -a start_url="http://duckduckgogg42xjoc72x3sjasowoarfbgcmvfimaftt6twagswzczad.onion"
```

##### **Problem:** Proxy connection failures
**Solution:**
```bash
# Run connectivity tests
python test_tor_connectivity.py
python test_socks5.py

# Check proxy health
python test_both_methods.py
```

#### **2. Database Issues**

##### **Problem:** Database corruption
**Solution:**
```bash
# Backup current database
cp darknet_intelligence.db darknet_intelligence.db.backup

# Verify database integrity
sqlite3 darknet_intelligence.db "PRAGMA integrity_check;"

# Recreate database if needed
python migrate_to_sqlite.py
```

##### **Problem:** Performance issues
**Solution:**
```sql
-- Optimize database
PRAGMA optimize;
PRAGMA vacuum;
PRAGMA analyze;
```

#### **3. Dashboard Issues**

##### **Problem:** Dashboard not loading
**Solution:**
```bash
# Check Streamlit installation
streamlit --version

# Clear cache
streamlit cache clear

# Restart dashboard
streamlit run dashboard.py --server.port 8501
```

##### **Problem:** Real-time updates not working
**Solution:**
```python
# Verify auto-refresh configuration
st_autorefresh(interval=30000, key="datarefresh")

# Check data file permissions
ls -la *.json *.db
```

### **Performance Optimization:**

#### **1. System Tuning**
```bash
# Increase file descriptor limits
ulimit -n 4096

# Optimize network settings
echo 'net.core.rmem_max = 16777216' >> /etc/sysctl.conf
echo 'net.core.wmem_max = 16777216' >> /etc/sysctl.conf
```

#### **2. Database Optimization**
```sql
-- Optimize database performance
PRAGMA cache_size = 10000;
PRAGMA temp_store = MEMORY;
PRAGMA mmap_size = 268435456;
```

---

## üìä SYSTEM METRICS & MONITORING

### Performance Metrics

#### **Key Performance Indicators:**
- **Crawling Speed:** Pages per minute
- **Alert Generation Rate:** Alerts per hour
- **Database Performance:** Query execution time
- **Proxy Health:** Connection success rate
- **System Resource Usage:** CPU and memory utilization

#### **Monitoring Tools:**
```python
# Real-time metrics collection
def collect_system_metrics():
    return {
        'cpu_usage': psutil.cpu_percent(),
        'memory_usage': psutil.virtual_memory().percent,
        'disk_usage': psutil.disk_usage('/').percent,
        'network_io': psutil.net_io_counters(),
        'crawler_status': get_crawler_status(),
        'database_health': check_database_health()
    }
```

### **Alerting System:**

#### **Alert Categories:**
- **System Alerts:** System performance and health
- **Security Alerts:** OPSEC and security violations
- **Operational Alerts:** Crawler and database issues
- **Intelligence Alerts:** Threat detection and analysis

#### **Alert Delivery:**
- **Telegram Integration:** Real-time Telegram notifications
- **Dashboard Alerts:** Visual alert display
- **Log File Alerts:** Comprehensive logging system
- **Email Notifications:** Optional email alerting

---

## üéñÔ∏è SECURITY CLASSIFICATIONS

### Data Classification Levels

#### **1. CONFIDENTIAL**
- **Threat Intelligence Data:** Collected threat information
- **Source URLs:** Visited .onion addresses
- **Keyword Matches:** Detected threat indicators
- **Alert Data:** Generated security alerts

#### **2. SECRET**
- **Operational Procedures:** Detailed operational protocols
- **Proxy Configurations:** Proxy chain configurations
- **OPSEC Protocols:** Security procedure details
- **System Architecture:** Detailed system design

#### **3. TOP SECRET**
- **Source Code:** Complete system source code
- **Encryption Keys:** System encryption keys
- **Access Credentials:** System access credentials
- **Intelligence Analysis:** Comprehensive threat analysis

### **Handling Procedures:**
- **Data Encryption:** All sensitive data encrypted at rest
- **Access Control:** Role-based access management
- **Audit Logging:** Comprehensive access logging
- **Secure Deletion:** Secure data destruction protocols

---

## üîó EXTERNAL INTEGRATIONS

### Third-Party Integrations

#### **1. Telegram Bot Integration**
```python
# Telegram alert configuration
TELEGRAM_BOT_TOKEN = "YOUR_BOT_TOKEN"
TELEGRAM_CHAT_ID = "YOUR_CHAT_ID"

# Alert message format
def send_telegram_alert(token, chat_id, message):
    """Send formatted alert to Telegram"""
```

#### **2. TOR Network Integration**
- **TOR Client:** Native TOR client integration
- **Circuit Management:** Automatic circuit refresh
- **Exit Node Selection:** Strategic exit node selection
- **Bridge Configuration:** TOR bridge support

#### **3. Proxy Services**
- **Privoxy Integration:** HTTP proxy support
- **SOCKS5 Support:** Advanced SOCKS5 integration
- **Proxy Chains:** Multi-proxy chaining support
- **VPN Integration:** Optional VPN support

### **API Endpoints:**
```python
# External API integration points
/api/alerts          # Alert management API
/api/crawler/status  # Crawler status API
/api/threat/intel    # Threat intelligence API
/api/system/health   # System health API
```

---

## üìà FUTURE ENHANCEMENTS

### Planned Features

#### **Phase 3 Enhancements:**
- **AI-Powered Analysis:** Machine learning threat detection
- **Advanced Visualization:** 3D threat mapping
- **Automated Response:** Intelligent response systems
- **Multi-Language Support:** International operation support

#### **Advanced Features:**
- **Blockchain Integration:** Cryptocurrency tracking
- **Social Network Analysis:** Relationship mapping
- **Predictive Analytics:** Threat prediction capabilities
- **Mobile Application:** Mobile monitoring interface

#### **Enterprise Features:**
- **Multi-Tenant Support:** Organization-level separation
- **Advanced Reporting:** Executive-level reporting
- **API Extensions:** Extended API capabilities
- **Cloud Integration:** Cloud deployment options

---

## üìû SUPPORT & CONTACT

### Technical Support

#### **Support Channels:**
- **Documentation:** Complete technical documentation
- **Issue Tracking:** GitHub issue tracking system
- **Community Support:** User community forums
- **Professional Support:** Commercial support options

#### **Contact Information:**
- **Developer:** VectorIndia1
- **Repository:** https://github.com/Vectorindia1/Trinetra2.0
- **Issues:** https://github.com/Vectorindia1/Trinetra2.0/issues
- **Wiki:** https://github.com/Vectorindia1/Trinetra2.0/wiki

---

## üìÑ LICENSE & LEGAL

### License Information

#### **Software License:**
- **Type:** Military-Grade Intelligence Platform
- **Usage:** Authorized personnel only
- **Distribution:** Restricted distribution
- **Modification:** Permitted with attribution

#### **Legal Considerations:**
- **Compliance:** Ensure legal compliance in jurisdiction
- **Ethics:** Ethical use guidelines
- **Responsibility:** User responsibility for operations
- **Liability:** Limited liability terms

### **Disclaimer:**
```
TRINETRA 2.0 is a military-grade intelligence platform designed for 
authorized security professionals. Users are responsible for ensuring 
compliance with applicable laws and regulations. The developers assume 
no responsibility for misuse or unauthorized deployment.
```

---

## üéØ CONCLUSION

TRINETRA 2.0 represents the pinnacle of darknet intelligence gathering technology, combining military-grade security with advanced automation and professional intelligence analysis capabilities. This comprehensive platform provides security professionals with the tools necessary to monitor, analyze, and respond to threats in the dark web ecosystem.

The system's modular architecture, comprehensive security features, and professional-grade interface make it suitable for military, law enforcement, and security research applications. With its advanced anonymity protection, real-time threat detection, and comprehensive reporting capabilities, TRINETRA 2.0 sets the standard for darknet intelligence operations.

**System Status:** OPERATIONAL  
**Classification:** MILITARY-GRADE  
**Deployment:** READY FOR OPERATIONS  

---

*Document Version: 2.0*  
*Last Updated: 2025-01-17*  
*Classification: CONFIDENTIAL*  
*Distribution: RESTRICTED*
